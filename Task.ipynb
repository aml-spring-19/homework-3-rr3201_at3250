{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (33,35,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset \n",
    "dir = 'subsample_data'\n",
    "data = pd.read_csv(dir,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 67 columns):\n",
      "Unnamed: 0                                                          10000 non-null object\n",
      "Unnamed: 1                                                          10000 non-null int64\n",
      "Physician_License_State_code2                                       123 non-null object\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5           59 non-null object\n",
      "Recipient_State                                                     9989 non-null object\n",
      "Recipient_Country                                                   9993 non-null object\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1           8205 non-null object\n",
      "Form_of_Payment_or_Transfer_of_Value                                10000 non-null object\n",
      "Associated_Drug_or_Biological_NDC_4                                 102 non-null object\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4           151 non-null object\n",
      "Covered_or_Noncovered_Indicator_3                                   467 non-null object\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5            59 non-null object\n",
      "Physician_Specialty                                                 5198 non-null object\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4            151 non-null object\n",
      "Date_of_Payment                                                     10000 non-null object\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3            457 non-null object\n",
      "Recipient_City                                                      9993 non-null object\n",
      "Teaching_Hospital_CCN                                               808 non-null float64\n",
      "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name           10000 non-null object\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2           1312 non-null object\n",
      "Total_Amount_of_Payment_USDollars                                   10000 non-null float64\n",
      "Related_Product_Indicator                                           10000 non-null object\n",
      "Covered_or_Noncovered_Indicator_4                                   151 non-null object\n",
      "Product_Category_or_Therapeutic_Area_4                              149 non-null object\n",
      "Dispute_Status_for_Publication                                      10000 non-null object\n",
      "Recipient_Primary_Business_Street_Address_Line1                     9993 non-null object\n",
      "Associated_Drug_or_Biological_NDC_3                                 364 non-null object\n",
      "Recipient_Province                                                  3 non-null object\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID         10000 non-null int64\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country    10000 non-null object\n",
      "Associated_Drug_or_Biological_NDC_2                                 1056 non-null object\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3           457 non-null object\n",
      "Delay_in_Publication_Indicator                                      10000 non-null object\n",
      "Physician_License_State_code4                                       4 non-null object\n",
      "Recipient_Postal_Code                                               4 non-null object\n",
      "Physician_License_State_code5                                       2 non-null object\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1            8168 non-null object\n",
      "Physician_First_Name                                                5205 non-null object\n",
      "Change_Type                                                         10000 non-null object\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2            1312 non-null object\n",
      "Payment_Publication_Date                                            10000 non-null object\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State      9442 non-null object\n",
      "Physician_Name_Suffix                                               123 non-null object\n",
      "Teaching_Hospital_ID                                                808 non-null float64\n",
      "Recipient_Zip_Code                                                  9989 non-null object\n",
      "Program_Year                                                        10000 non-null int64\n",
      "Physician_Primary_Type                                              5205 non-null object\n",
      "Recipient_Primary_Business_Street_Address_Line2                     3142 non-null object\n",
      "Covered_or_Noncovered_Indicator_5                                   59 non-null object\n",
      "Physician_License_State_code1                                       5205 non-null object\n",
      "Physician_Last_Name                                                 5205 non-null object\n",
      "Record_ID                                                           10000 non-null int64\n",
      "Covered_or_Noncovered_Indicator_2                                   1367 non-null object\n",
      "Product_Category_or_Therapeutic_Area_2                              1309 non-null object\n",
      "Physician_Middle_Name                                               3051 non-null object\n",
      "Product_Category_or_Therapeutic_Area_3                              455 non-null object\n",
      "Associated_Drug_or_Biological_NDC_5                                 16 non-null object\n",
      "Associated_Drug_or_Biological_NDC_1                                 6117 non-null object\n",
      "Covered_Recipient_Type                                              10000 non-null object\n",
      "Product_Category_or_Therapeutic_Area_5                              57 non-null object\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name       10000 non-null object\n",
      "Physician_License_State_code3                                       28 non-null object\n",
      "Product_Category_or_Therapeutic_Area_1                              7949 non-null object\n",
      "Physician_Profile_ID                                                5205 non-null float64\n",
      "Covered_or_Noncovered_Indicator_1                                   9101 non-null object\n",
      "Teaching_Hospital_Name                                              808 non-null object\n",
      "Target                                                              10000 non-null int64\n",
      "dtypes: float64(4), int64(5), object(58)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check data info\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the datset into the targeted feature and predictive features\n",
    "target = data['Target']\n",
    "features = data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a pairplot for all numeric features to see distribution trends and other important elements\n",
    "numerics = features._get_numeric_data()\n",
    "\n",
    "# sns.pairplot(numerics,size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check the number of missing values of numeric features\n",
    "num = numerics.isnull().sum()\n",
    "\n",
    "#Extract columns which have fewer than 5000 nulls\n",
    "num_name = []\n",
    "for i in range(len(num)):\n",
    "    if(num[i-1] < 5000):\n",
    "        num_name.append(num.index.tolist()[i-1])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#Create the dataframe for numeric variables , create a new dataframe named num_name, and store each variable's name   \n",
    "temp = data[num_name]\n",
    "temp.head()\n",
    "num_temp = temp[['Unnamed: 1','Total_Amount_of_Payment_USDollars']]\n",
    "num_name = list(num_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 1',\n",
       " 'Teaching_Hospital_CCN',\n",
       " 'Total_Amount_of_Payment_USDollars',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID',\n",
       " 'Teaching_Hospital_ID',\n",
       " 'Program_Year',\n",
       " 'Record_ID',\n",
       " 'Physician_Profile_ID']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the list of names of numeric features\n",
    "numeric_features = list(numerics)\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Physician_License_State_code2',\n",
       " 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5',\n",
       " 'Recipient_State',\n",
       " 'Recipient_Country',\n",
       " 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Form_of_Payment_or_Transfer_of_Value',\n",
       " 'Associated_Drug_or_Biological_NDC_4',\n",
       " 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4',\n",
       " 'Covered_or_Noncovered_Indicator_3',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5',\n",
       " 'Physician_Specialty',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4',\n",
       " 'Date_of_Payment',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3',\n",
       " 'Recipient_City',\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
       " 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2',\n",
       " 'Related_Product_Indicator',\n",
       " 'Covered_or_Noncovered_Indicator_4',\n",
       " 'Product_Category_or_Therapeutic_Area_4',\n",
       " 'Dispute_Status_for_Publication',\n",
       " 'Recipient_Primary_Business_Street_Address_Line1',\n",
       " 'Associated_Drug_or_Biological_NDC_3',\n",
       " 'Recipient_Province',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
       " 'Associated_Drug_or_Biological_NDC_2',\n",
       " 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3',\n",
       " 'Delay_in_Publication_Indicator',\n",
       " 'Physician_License_State_code4',\n",
       " 'Recipient_Postal_Code',\n",
       " 'Physician_License_State_code5',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Physician_First_Name',\n",
       " 'Change_Type',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2',\n",
       " 'Payment_Publication_Date',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
       " 'Physician_Name_Suffix',\n",
       " 'Recipient_Zip_Code',\n",
       " 'Physician_Primary_Type',\n",
       " 'Recipient_Primary_Business_Street_Address_Line2',\n",
       " 'Covered_or_Noncovered_Indicator_5',\n",
       " 'Physician_License_State_code1',\n",
       " 'Physician_Last_Name',\n",
       " 'Covered_or_Noncovered_Indicator_2',\n",
       " 'Product_Category_or_Therapeutic_Area_2',\n",
       " 'Physician_Middle_Name',\n",
       " 'Product_Category_or_Therapeutic_Area_3',\n",
       " 'Associated_Drug_or_Biological_NDC_5',\n",
       " 'Associated_Drug_or_Biological_NDC_1',\n",
       " 'Covered_Recipient_Type',\n",
       " 'Product_Category_or_Therapeutic_Area_5',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name',\n",
       " 'Physician_License_State_code3',\n",
       " 'Product_Category_or_Therapeutic_Area_1',\n",
       " 'Covered_or_Noncovered_Indicator_1',\n",
       " 'Teaching_Hospital_Name']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract categorical features and store the list of names of categorical features\n",
    "categoricals = features.select_dtypes(include='object')\n",
    "categorical_features = list(categoricals)\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the number of missing values of categorical features\n",
    "categ = categoricals.isnull().sum()\n",
    "\n",
    "#Extract columns which have fewer than 5000 nulls\n",
    "categ_name = []\n",
    "for i in range(len(categ)):\n",
    "    if(categ[i-1] < 5000):\n",
    "        categ_name.append(categ.index.tolist()[i-1])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#Create the dataframe for categorical variables, create a new dataframe named categ_name, and store each variable's name   \n",
    "categ_temp = data[categ_name]\n",
    "categ_name = list(categ_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 1', 'Total_Amount_of_Payment_USDollars']\n",
      "['Unnamed: 0', 'Recipient_State', 'Recipient_Country', 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1', 'Form_of_Payment_or_Transfer_of_Value', 'Physician_Specialty', 'Date_of_Payment', 'Recipient_City', 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name', 'Related_Product_Indicator', 'Dispute_Status_for_Publication', 'Recipient_Primary_Business_Street_Address_Line1', 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country', 'Delay_in_Publication_Indicator', 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1', 'Physician_First_Name', 'Change_Type', 'Payment_Publication_Date', 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State', 'Recipient_Zip_Code', 'Physician_Primary_Type', 'Physician_License_State_code1', 'Physician_Last_Name', 'Associated_Drug_or_Biological_NDC_1', 'Covered_Recipient_Type', 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', 'Product_Category_or_Therapeutic_Area_1', 'Covered_or_Noncovered_Indicator_1']\n"
     ]
    }
   ],
   "source": [
    "#Concatenate num_temp and categ_temp\n",
    "new = pd.concat([num_temp,categ_temp],axis=1)\n",
    "print(num_name)\n",
    "print(categ_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_categories = []\n",
    "for a in categ_name:\n",
    "    print(a,len(data[a].unique()))\n",
    "    if len(data[a].unique()) > 50:\n",
    "        remove_categories.append(a)\n",
    "print(remove_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Recipient_State',\n",
       " 'Recipient_Country',\n",
       " 'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Form_of_Payment_or_Transfer_of_Value',\n",
       " 'Physician_Specialty',\n",
       " 'Date_of_Payment',\n",
       " 'Recipient_City',\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
       " 'Related_Product_Indicator',\n",
       " 'Dispute_Status_for_Publication',\n",
       " 'Recipient_Primary_Business_Street_Address_Line1',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
       " 'Delay_in_Publication_Indicator',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Physician_First_Name',\n",
       " 'Change_Type',\n",
       " 'Payment_Publication_Date',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
       " 'Recipient_Zip_Code',\n",
       " 'Physician_Primary_Type',\n",
       " 'Physician_License_State_code1',\n",
       " 'Physician_Last_Name',\n",
       " 'Associated_Drug_or_Biological_NDC_1',\n",
       " 'Covered_Recipient_Type',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name',\n",
       " 'Product_Category_or_Therapeutic_Area_1',\n",
       " 'Covered_or_Noncovered_Indicator_1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "categ_name_copy = deepcopy(categ_name)\n",
    "\n",
    "print(\"Baseline Logistic Regression for :\")\n",
    "for c in categ_name_copy:\n",
    "    categ_name = [c]\n",
    "    #Build a pipeline to handle the numeric features\n",
    "    numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "    #Build a pipeline to handle the categorical features\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                           ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    #Build a column transformer to apply transformers above to the given dataset\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_name),\n",
    "            ('cat', categorical_transformer, categ_name)])\n",
    "\n",
    "    #Create a pipeline which contains our model\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier',LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "    #Split the dataset into the training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new, target, stratify=target, test_size=0.3)\n",
    "\n",
    "    #Cross validation \n",
    "    scores = cross_val_score(clf,X_train, y_train, cv=5)\n",
    "    scores = sum(scores) / float(len(scores))\n",
    "    print(c,scores)\n",
    "\n",
    "categ_name = deepcopy(categ_name_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "    #Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                           #('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "                                         ])\n",
    "\n",
    "    #Build a column transformer to apply transformers above to the given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, ['Recipient_State'])])\n",
    "\n",
    "rs = preprocessor.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1', 'Form_of_Payment_or_Transfer_of_Value', 'Date_of_Payment', 'Related_Product_Indicator', 'Dispute_Status_for_Publication', 'Delay_in_Publication_Indicator', 'Change_Type', 'Payment_Publication_Date', 'Covered_or_Noncovered_Indicator_1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Logistic Regression : 0.8517142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "above_98 = ['Unnamed: 0','Physician_Specialty','Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1','Physician_First_Name','Physician_Primary_Type',\n",
    "            'Physician_License_State_code1','Physician_Last_Name','Associated_Drug_or_Biological_NDC_1','Covered_Recipient_Type',\n",
    "            'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', 'Product_Category_or_Therapeutic_Area_1']\n",
    "rec_details = ['Recipient_State', 'Recipient_Country','Recipient_City','Recipient_Primary_Business_Street_Address_Line1',\n",
    "              'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country','Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
    "              'Recipient_Zip_Code']\n",
    "num_name = []\n",
    "categ_name_copy = deepcopy(categ_name)\n",
    "remove_list = above_98 + rec_details\n",
    "for a in remove_list:\n",
    "    if a in categ_name_copy:\n",
    "        categ_name_copy.remove(a)\n",
    "\n",
    "print(categ_name_copy)\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to the given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_name),\n",
    "        ('cat', categorical_transformer, categ_name_copy)])\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier',LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "#Split the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(new, target, stratify=target, test_size=0.3)\n",
    "\n",
    "#Cross validation \n",
    "scores = cross_val_score(clf,X_train, y_train, cv=5)\n",
    "scores = sum(scores) / float(len(scores))\n",
    "print(\"Baseline Logistic Regression :\",scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Form_of_Payment_or_Transfer_of_Value',\n",
       " 'Date_of_Payment',\n",
       " 'Related_Product_Indicator',\n",
       " 'Dispute_Status_for_Publication',\n",
       " 'Delay_in_Publication_Indicator',\n",
       " 'Change_Type',\n",
       " 'Payment_Publication_Date',\n",
       " 'Covered_or_Noncovered_Indicator_1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_name_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1', 'Form_of_Payment_or_Transfer_of_Value', 'Date_of_Payment', 'Related_Product_Indicator', 'Dispute_Status_for_Publication', 'Delay_in_Publication_Indicator', 'Change_Type', 'Payment_Publication_Date', 'Covered_or_Noncovered_Indicator_1']\n",
      "Baseline Logistic Regression : 0.8255714285714285\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "above_98 = ['Unnamed: 0','Physician_Specialty','Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1','Physician_First_Name','Physician_Primary_Type',\n",
    "            'Physician_License_State_code1','Physician_Last_Name','Associated_Drug_or_Biological_NDC_1','Covered_Recipient_Type',\n",
    "            'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', 'Product_Category_or_Therapeutic_Area_1']\n",
    "rec_details = ['Recipient_State', 'Recipient_Country','Recipient_City','Recipient_Primary_Business_Street_Address_Line1',\n",
    "              'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country','Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
    "              'Recipient_Zip_Code']\n",
    "num_name = []\n",
    "categ_name_copy = deepcopy(categ_name)\n",
    "remove_list = above_98 + rec_details\n",
    "for a in remove_list:\n",
    "    if a in categ_name_copy:\n",
    "        categ_name_copy.remove(a)\n",
    "\n",
    "print(categ_name_copy)\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to the given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_name),\n",
    "        ('cat', categorical_transformer, categ_name_copy)])\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier',RandomForestClassifier(n_estimators=10, max_depth=2,random_state=0))])\n",
    "\n",
    "#Split the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(new, target, stratify=target, test_size=0.3)\n",
    "\n",
    "#Cross validation \n",
    "scores = cross_val_score(clf,X_train, y_train, cv=5)\n",
    "scores = sum(scores) / float(len(scores))\n",
    "print(\"Baseline Logistic Regression :\",scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a pipeline to handle the numeric features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators=50, max_depth=2,random_state=0))])\n",
    "\n",
    "#Split the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.3)\n",
    "\n",
    "#Cross validation \n",
    "scores = cross_val_score(clf,X_train, y_train, cv=10)\n",
    "scores = sum(scores) / float(len(scores))\n",
    "print(\"Random Forest:\")\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Random Forest (There is a bug, and I am working on this)\n",
    "target_name = list(target)\n",
    "export_graphviz(clf.steps[1][1].estimators_, out_file='tree.dot', \n",
    "                feature_names = names,\n",
    "                class_names = target_name,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check feature importances for each features with the Random Forest \n",
    "#Need to figure out what's wrong with this (all feature importances are 0.0)\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(max_depth=125, max_features=3,\n",
    "                                                            min_samples_leaf=3,min_samples_split=10,\n",
    "                                                           n_estimators=100))])\n",
    "\n",
    "\n",
    "names = list(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), clf.steps[1][1].feature_importances_), names),reverse = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "#Build a pipeline to handle the numeric features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', SVC(gamma='scale'))])\n",
    "\n",
    "#Split the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.3)\n",
    "\n",
    "#Cross validation \n",
    "scores = cross_val_score(clf,X_train, y_train, cv=10)\n",
    "scores = sum(scores) / float(len(scores))\n",
    "print(\"SVC:\")\n",
    "print(scores)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "#Build a pipeline to handle the numeric features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', Lasso(alpha=0.05))])\n",
    "\n",
    "#Split the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.3)\n",
    "\n",
    "#Cross validation \n",
    "scores = cross_val_score(clf,X_train, y_train, cv=10)\n",
    "scores = sum(scores) / float(len(scores))\n",
    "print(\"Lasso :\")\n",
    "print(scores)\n",
    "\n",
    "\n",
    "# In[123]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2563"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Recipient_City'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE CLASSIFIER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1', 'Form_of_Payment_or_Transfer_of_Value', 'Date_of_Payment', 'Related_Product_Indicator', 'Dispute_Status_for_Publication', 'Delay_in_Publication_Indicator', 'Change_Type', 'Payment_Publication_Date', 'Covered_or_Noncovered_Indicator_1']\n",
      "Score 0.9971289795918368\n",
      "Best params {'classifier__alpha': 1.0}\n",
      "[[1436   64]\n",
      " [  13 1487]]\n",
      "0.9743333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.linear_model import Lasso,RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "above_98 = ['Unnamed: 0','Physician_Specialty','Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1','Physician_First_Name','Physician_Primary_Type',\n",
    "            'Physician_License_State_code1','Physician_Last_Name','Associated_Drug_or_Biological_NDC_1','Covered_Recipient_Type',\n",
    "            'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', 'Product_Category_or_Therapeutic_Area_1']\n",
    "rec_details = ['Recipient_State', 'Recipient_Country','Recipient_City','Recipient_Primary_Business_Street_Address_Line1',\n",
    "              'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country','Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
    "              'Recipient_Zip_Code']\n",
    "num_name = []\n",
    "categ_name_copy = deepcopy(categ_name)\n",
    "remove_list = above_98 + rec_details\n",
    "for a in remove_list:\n",
    "    if a in categ_name_copy:\n",
    "        categ_name_copy.remove(a)\n",
    "\n",
    "print(categ_name_copy)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.3,shuffle=True)\n",
    "\n",
    "#Build a pipeline to handle the numeric features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categ_name_copy)])\n",
    "\n",
    "param_grid = {'classifier__alpha': np.logspace(-3, 0, 5)}\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RidgeClassifier())])\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid,cv=10, scoring='roc_auc')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Score', grid.best_score_)\n",
    "print('Best params',grid.best_params_)\n",
    "\n",
    "\n",
    "ridge = RidgeClassifier(alpha=grid.best_params_['classifier__alpha'])\n",
    "final_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', ridge)])\n",
    "final_pipe.fit(X_train, y_train)\n",
    "y_pred = final_pipe.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#print(final_pipe.named_steps['classifier'].coef_)\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "# x = np.argsort(np.absolute(final_pipe.named_steps['classifier'].coef_[0]))\n",
    "# preprocessor.transformers_[1][1].named_steps.onehot.get_feature_names(categorical_features)[3]\n",
    "\n",
    "# l = list(preprocessor.transformers_[0][2]) \n",
    "# len(list(preprocessor.transformers_[1][2]))#.named_steps.onehot.get_feature_names(categorical_features)[3]\n",
    "# for i in range(5):\n",
    "#     print(l[x[i]])\n",
    "# pd.Series(final_pipe.named_steps['classifier'].coef_[0])\n",
    "\n",
    "# f = np.argsort(np.absolute(final_pipe.named_steps['classifier'].coef_[0]))[:5]\n",
    "# preprocessor.transformers_[1][1].named_steps.onehot.get_features_names(categorical_features)[5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1', 'Form_of_Payment_or_Transfer_of_Value', 'Date_of_Payment', 'Related_Product_Indicator', 'Dispute_Status_for_Publication', 'Delay_in_Publication_Indicator', 'Change_Type', 'Payment_Publication_Date', 'Covered_or_Noncovered_Indicator_1']\n",
      "Score 0.9995510204081633\n",
      "Best params {'classifier__max_depth': 9, 'classifier__n_estimators': 250}\n",
      "[[1478   22]\n",
      " [  12 1488]]\n",
      "0.9886666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.linear_model import Lasso,RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "above_98 = ['Unnamed: 0','Physician_Specialty','Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1','Physician_First_Name','Physician_Primary_Type',\n",
    "            'Physician_License_State_code1','Physician_Last_Name','Associated_Drug_or_Biological_NDC_1','Covered_Recipient_Type',\n",
    "            'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', 'Product_Category_or_Therapeutic_Area_1']\n",
    "rec_details = ['Recipient_State', 'Recipient_Country','Recipient_City','Recipient_Primary_Business_Street_Address_Line1',\n",
    "              'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country','Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
    "              'Recipient_Zip_Code']\n",
    "num_name = []\n",
    "categ_name_copy = deepcopy(categ_name)\n",
    "remove_list = above_98 + rec_details\n",
    "for a in remove_list:\n",
    "    if a in categ_name_copy:\n",
    "        categ_name_copy.remove(a)\n",
    "\n",
    "print(categ_name_copy)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.3,shuffle=True)\n",
    "\n",
    "#Build a pipeline to handle the numeric features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "#Build a pipeline to handle the categorical features\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                       ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Build a column transformer to apply transformers above to given dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categ_name_copy)])\n",
    "\n",
    "param_grid = {'classifier__n_estimators': range(50, 300, 50),\n",
    "             'classifier__max_depth' : range(1,10)}\n",
    "\n",
    "#Create a pipeline which contains our model\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid,cv=10, scoring='roc_auc')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Score', grid.best_score_)\n",
    "print('Best params',grid.best_params_)\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=grid.best_params_['classifier__n_estimators'],\n",
    "                               max_depth=grid.best_params_['classifier__max_depth'],random_state=0)\n",
    "final_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', rfc)])\n",
    "final_pipe.fit(X_train, y_train)\n",
    "y_pred = final_pipe.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#print(final_pipe.named_steps['classifier'].coef_)\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "# x = np.argsort(np.absolute(final_pipe.named_steps['classifier'].coef_[0]))\n",
    "# preprocessor.transformers_[1][1].named_steps.onehot.get_feature_names(categorical_features)[3]\n",
    "\n",
    "# l = list(preprocessor.transformers_[0][2]) \n",
    "# len(list(preprocessor.transformers_[1][2]))#.named_steps.onehot.get_feature_names(categorical_features)[3]\n",
    "# for i in range(5):\n",
    "#     print(l[x[i]])\n",
    "# pd.Series(final_pipe.named_steps['classifier'].coef_[0])\n",
    "\n",
    "# f = np.argsort(np.absolute(final_pipe.named_steps['classifier'].coef_[0]))[:5]\n",
    "# preprocessor.transformers_[1][1].named_steps.onehot.get_features_names(categorical_features)[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
